{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created CSV: juliet_dataset.csv with 16149 rows.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Root directory containing all CWE folders\n",
    "JULIET_ROOT = \"juliet/testcases\"\n",
    "\n",
    "# Weâ€™ll store rows in a list of dicts, each dict has 'code' and 'label'\n",
    "dataset_rows = []\n",
    "\n",
    "for cwe_folder in os.listdir(JULIET_ROOT):\n",
    "    full_cwe_path = os.path.join(JULIET_ROOT, cwe_folder)\n",
    "\n",
    "    # Skip if it's not a directory\n",
    "    if not os.path.isdir(full_cwe_path):\n",
    "        continue\n",
    "\n",
    "    # This is a simplistic approach:\n",
    "    # Let's assume \"CWE###\" in folder name => \"vulnerable\" label\n",
    "    # but you can refine logic to handle \"safe\" vs. \"vulnerable\" testcases\n",
    "    label = \"vulnerable\"  # or you can do a multi-label approach based on `cwe_folder`\n",
    "\n",
    "    # Now gather the .c/.cpp files\n",
    "    for file_name in os.listdir(full_cwe_path):\n",
    "        if file_name.endswith(\".c\") or file_name.endswith(\".cpp\"):\n",
    "            file_path = os.path.join(full_cwe_path, file_name)\n",
    "\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "                code_content = f.read()\n",
    "\n",
    "                # Build a row\n",
    "                row_dict = {\n",
    "                    \"code\": code_content,\n",
    "                    \"label\": label\n",
    "                }\n",
    "                dataset_rows.append(row_dict)\n",
    "\n",
    "# Finally, write to CSV\n",
    "csv_file = \"juliet_dataset.csv\"\n",
    "with open(csv_file, mode=\"w\", newline='', encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"code\", \"label\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(dataset_rows)\n",
    "\n",
    "print(f\"Created CSV: {csv_file} with {len(dataset_rows)} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944a90a8bb6d4d0b8294b99458fdf5be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "304f91b93a0a4cb388c76cf09a16cc5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3230 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 12919\n",
      "Eval dataset size: 3230\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7277170e67644f4a6e769187ed79c18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e80e7e39644b66a079a1925e28a2f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3230 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at /Users/ehsan/.llama/checkpoints/Llama3.2-1B-hf and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/8r/rpjp5yn171789b8drccyr0nc0000gn/T/ipykernel_25595/1909155078.py:123: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA-wrapped model created.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24788a4fe45d43858af309f9b3bd9534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4845 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3161, 'grad_norm': 0.17329414188861847, 'learning_rate': 9.958720330237359e-05, 'epoch': 0.01}\n",
      "{'loss': 0.0113, 'grad_norm': 0.5253696441650391, 'learning_rate': 9.917440660474717e-05, 'epoch': 0.02}\n",
      "{'loss': 0.0007, 'grad_norm': 3.121109330095351e-05, 'learning_rate': 9.876160990712075e-05, 'epoch': 0.04}\n",
      "{'loss': 0.0, 'grad_norm': 4.585513306665234e-05, 'learning_rate': 9.834881320949433e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0, 'grad_norm': 6.393916555680335e-05, 'learning_rate': 9.793601651186791e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0, 'grad_norm': 1.1325458217470441e-05, 'learning_rate': 9.75232198142415e-05, 'epoch': 0.07}\n",
      "{'loss': 0.0, 'grad_norm': 0.0009136826847679913, 'learning_rate': 9.711042311661507e-05, 'epoch': 0.09}\n",
      "{'loss': 0.0, 'grad_norm': 0.0006551204132847488, 'learning_rate': 9.669762641898865e-05, 'epoch': 0.1}\n",
      "{'loss': 0.0, 'grad_norm': 8.667825568409171e-06, 'learning_rate': 9.628482972136223e-05, 'epoch': 0.11}\n",
      "{'loss': 0.0, 'grad_norm': 0.0005751991411671042, 'learning_rate': 9.587203302373582e-05, 'epoch': 0.12}\n",
      "{'loss': 0.0001, 'grad_norm': 8.116512617561966e-06, 'learning_rate': 9.54592363261094e-05, 'epoch': 0.14}\n",
      "{'loss': 0.0, 'grad_norm': 8.170539445018221e-08, 'learning_rate': 9.504643962848298e-05, 'epoch': 0.15}\n",
      "{'loss': 0.0, 'grad_norm': 3.3042200811905786e-05, 'learning_rate': 9.463364293085656e-05, 'epoch': 0.16}\n",
      "{'loss': 0.0, 'grad_norm': 0.0031791115179657936, 'learning_rate': 9.422084623323014e-05, 'epoch': 0.17}\n",
      "{'loss': 0.0, 'grad_norm': 1.0494661637494573e-06, 'learning_rate': 9.380804953560372e-05, 'epoch': 0.19}\n",
      "{'loss': 0.0, 'grad_norm': 0.0013777712592855096, 'learning_rate': 9.33952528379773e-05, 'epoch': 0.2}\n",
      "{'loss': 0.0, 'grad_norm': 0.0017983668949455023, 'learning_rate': 9.298245614035089e-05, 'epoch': 0.21}\n",
      "{'loss': 0.0, 'grad_norm': 0.00020359350310172886, 'learning_rate': 9.256965944272447e-05, 'epoch': 0.22}\n",
      "{'loss': 0.0, 'grad_norm': 8.585116120229941e-07, 'learning_rate': 9.215686274509804e-05, 'epoch': 0.24}\n",
      "{'loss': 0.0, 'grad_norm': 0.0001332968386122957, 'learning_rate': 9.174406604747162e-05, 'epoch': 0.25}\n",
      "{'loss': 0.0, 'grad_norm': 0.00010133258911082521, 'learning_rate': 9.13312693498452e-05, 'epoch': 0.26}\n",
      "{'loss': 0.0, 'grad_norm': 7.7505421359092e-05, 'learning_rate': 9.09184726522188e-05, 'epoch': 0.27}\n",
      "{'loss': 0.0, 'grad_norm': 5.560973477258813e-06, 'learning_rate': 9.050567595459238e-05, 'epoch': 0.28}\n",
      "{'loss': 0.0, 'grad_norm': 1.761747080308851e-05, 'learning_rate': 9.009287925696595e-05, 'epoch': 0.3}\n",
      "{'loss': 0.0, 'grad_norm': 2.6219189749099314e-05, 'learning_rate': 8.968008255933953e-05, 'epoch': 0.31}\n",
      "{'loss': 0.0, 'grad_norm': 1.275171371162287e-06, 'learning_rate': 8.926728586171311e-05, 'epoch': 0.32}\n",
      "{'loss': 0.0, 'grad_norm': 9.261713671548932e-07, 'learning_rate': 8.885448916408669e-05, 'epoch': 0.33}\n",
      "{'loss': 0.0, 'grad_norm': 6.478809382315376e-07, 'learning_rate': 8.844169246646027e-05, 'epoch': 0.35}\n",
      "{'loss': 0.0, 'grad_norm': 1.443614792151493e-07, 'learning_rate': 8.802889576883386e-05, 'epoch': 0.36}\n",
      "{'loss': 0.0, 'grad_norm': 4.457085651665693e-07, 'learning_rate': 8.761609907120744e-05, 'epoch': 0.37}\n",
      "{'loss': 0.0, 'grad_norm': 1.5247288501996081e-05, 'learning_rate': 8.720330237358102e-05, 'epoch': 0.38}\n",
      "{'loss': 0.0, 'grad_norm': 2.9735625162174983e-07, 'learning_rate': 8.679050567595459e-05, 'epoch': 0.4}\n",
      "{'loss': 0.0, 'grad_norm': 1.465469381400908e-07, 'learning_rate': 8.637770897832817e-05, 'epoch': 0.41}\n",
      "{'loss': 0.0, 'grad_norm': 4.985688974556979e-06, 'learning_rate': 8.596491228070177e-05, 'epoch': 0.42}\n",
      "{'loss': 0.0, 'grad_norm': 4.213033207633998e-06, 'learning_rate': 8.555211558307535e-05, 'epoch': 0.43}\n",
      "{'loss': 0.0, 'grad_norm': 1.1469769560790155e-06, 'learning_rate': 8.513931888544892e-05, 'epoch': 0.45}\n",
      "{'loss': 0.0, 'grad_norm': 1.5543731990419474e-07, 'learning_rate': 8.47265221878225e-05, 'epoch': 0.46}\n",
      "{'loss': 0.0, 'grad_norm': 1.5263086652339553e-06, 'learning_rate': 8.431372549019608e-05, 'epoch': 0.47}\n",
      "{'loss': 0.0, 'grad_norm': 4.5536776127619305e-08, 'learning_rate': 8.390092879256966e-05, 'epoch': 0.48}\n",
      "{'loss': 0.0, 'grad_norm': 3.999310501967557e-05, 'learning_rate': 8.348813209494324e-05, 'epoch': 0.5}\n",
      "{'loss': 0.0, 'grad_norm': 0.0001968168216990307, 'learning_rate': 8.307533539731683e-05, 'epoch': 0.51}\n",
      "{'loss': 0.0, 'grad_norm': 5.889749081688933e-05, 'learning_rate': 8.266253869969041e-05, 'epoch': 0.52}\n",
      "{'loss': 0.0, 'grad_norm': 5.600147687800927e-07, 'learning_rate': 8.224974200206399e-05, 'epoch': 0.53}\n",
      "{'loss': 0.0, 'grad_norm': 9.07123308024893e-07, 'learning_rate': 8.183694530443757e-05, 'epoch': 0.54}\n",
      "{'loss': 0.0, 'grad_norm': 2.29506658797618e-05, 'learning_rate': 8.142414860681114e-05, 'epoch': 0.56}\n",
      "{'loss': 0.0, 'grad_norm': 6.10622166163921e-08, 'learning_rate': 8.101135190918474e-05, 'epoch': 0.57}\n",
      "{'loss': 0.0, 'grad_norm': 6.537025569741672e-07, 'learning_rate': 8.059855521155832e-05, 'epoch': 0.58}\n",
      "{'loss': 0.0, 'grad_norm': 3.552155476427288e-07, 'learning_rate': 8.01857585139319e-05, 'epoch': 0.59}\n",
      "{'loss': 0.0, 'grad_norm': 1.6334746760549024e-05, 'learning_rate': 7.977296181630547e-05, 'epoch': 0.61}\n",
      "{'loss': 0.0, 'grad_norm': 0.0005970800993964076, 'learning_rate': 7.936016511867905e-05, 'epoch': 0.62}\n",
      "{'loss': 0.0, 'grad_norm': 1.1508542030469471e-07, 'learning_rate': 7.894736842105263e-05, 'epoch': 0.63}\n",
      "{'loss': 0.0, 'grad_norm': 3.8746911741327494e-06, 'learning_rate': 7.853457172342621e-05, 'epoch': 0.64}\n",
      "{'loss': 0.0, 'grad_norm': 1.1108833177786437e-06, 'learning_rate': 7.81217750257998e-05, 'epoch': 0.66}\n",
      "{'loss': 0.0, 'grad_norm': 1.427266056452936e-06, 'learning_rate': 7.770897832817338e-05, 'epoch': 0.67}\n",
      "{'loss': 0.0, 'grad_norm': 1.4542129065375775e-06, 'learning_rate': 7.729618163054696e-05, 'epoch': 0.68}\n",
      "{'loss': 0.0, 'grad_norm': 6.388117412825522e-07, 'learning_rate': 7.688338493292054e-05, 'epoch': 0.69}\n",
      "{'loss': 0.0, 'grad_norm': 1.8400830867904006e-06, 'learning_rate': 7.647058823529411e-05, 'epoch': 0.71}\n",
      "{'loss': 0.0, 'grad_norm': 4.041328907078423e-07, 'learning_rate': 7.605779153766769e-05, 'epoch': 0.72}\n",
      "{'loss': 0.0, 'grad_norm': 0.00016847577353473753, 'learning_rate': 7.564499484004129e-05, 'epoch': 0.73}\n",
      "{'loss': 0.0, 'grad_norm': 5.160245564184152e-07, 'learning_rate': 7.523219814241487e-05, 'epoch': 0.74}\n",
      "{'loss': 0.0, 'grad_norm': 3.926475073967595e-06, 'learning_rate': 7.481940144478845e-05, 'epoch': 0.76}\n",
      "{'loss': 0.0, 'grad_norm': 0.004267091862857342, 'learning_rate': 7.440660474716202e-05, 'epoch': 0.77}\n",
      "{'loss': 0.0, 'grad_norm': 0.000296809826977551, 'learning_rate': 7.39938080495356e-05, 'epoch': 0.78}\n",
      "{'loss': 0.0, 'grad_norm': 2.643256102885516e-08, 'learning_rate': 7.358101135190918e-05, 'epoch': 0.79}\n",
      "{'loss': 0.0, 'grad_norm': 4.0279130075759895e-07, 'learning_rate': 7.316821465428278e-05, 'epoch': 0.8}\n",
      "{'loss': 0.0, 'grad_norm': 1.1613753940764582e-06, 'learning_rate': 7.275541795665635e-05, 'epoch': 0.82}\n",
      "{'loss': 0.0, 'grad_norm': 1.6854083639827877e-07, 'learning_rate': 7.234262125902993e-05, 'epoch': 0.83}\n",
      "{'loss': 0.0, 'grad_norm': 0.0001857128372648731, 'learning_rate': 7.192982456140351e-05, 'epoch': 0.84}\n",
      "{'loss': 0.0, 'grad_norm': 4.092604513061815e-07, 'learning_rate': 7.15170278637771e-05, 'epoch': 0.85}\n",
      "{'loss': 0.0, 'grad_norm': 2.4216415113187395e-05, 'learning_rate': 7.110423116615066e-05, 'epoch': 0.87}\n",
      "{'loss': 0.0, 'grad_norm': 2.440297066641506e-07, 'learning_rate': 7.069143446852426e-05, 'epoch': 0.88}\n",
      "{'loss': 0.0, 'grad_norm': 1.420440014499036e-07, 'learning_rate': 7.027863777089784e-05, 'epoch': 0.89}\n",
      "{'loss': 0.0, 'grad_norm': 4.2808665057236794e-06, 'learning_rate': 6.986584107327142e-05, 'epoch': 0.9}\n",
      "{'loss': 0.0, 'grad_norm': 2.957589276775252e-05, 'learning_rate': 6.945304437564499e-05, 'epoch': 0.92}\n",
      "{'loss': 0.0, 'grad_norm': 2.8606853774704177e-08, 'learning_rate': 6.904024767801857e-05, 'epoch': 0.93}\n",
      "{'loss': 0.0, 'grad_norm': 8.681708152380452e-08, 'learning_rate': 6.862745098039216e-05, 'epoch': 0.94}\n",
      "{'loss': 0.0, 'grad_norm': 3.3115739483946527e-07, 'learning_rate': 6.821465428276575e-05, 'epoch': 0.95}\n",
      "{'loss': 0.0, 'grad_norm': 6.05980758905389e-08, 'learning_rate': 6.780185758513932e-05, 'epoch': 0.97}\n",
      "{'loss': 0.0, 'grad_norm': 3.511128809918773e-08, 'learning_rate': 6.73890608875129e-05, 'epoch': 0.98}\n",
      "{'loss': 0.0, 'grad_norm': 5.09253254676878e-07, 'learning_rate': 6.697626418988648e-05, 'epoch': 0.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aed1281fb6649948546266b5e217955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/808 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.04194684178583e-08, 'eval_accuracy': 1.0, 'eval_f1': 1.0, 'eval_runtime': 2170.6947, 'eval_samples_per_second': 1.488, 'eval_steps_per_second': 0.372, 'epoch': 1.0}\n",
      "{'loss': 0.0, 'grad_norm': 4.880199071521929e-07, 'learning_rate': 6.656346749226007e-05, 'epoch': 1.0}\n",
      "{'loss': 0.0, 'grad_norm': 5.196587267164432e-07, 'learning_rate': 6.615067079463365e-05, 'epoch': 1.02}\n",
      "{'loss': 0.0, 'grad_norm': 1.0422053264846909e-07, 'learning_rate': 6.573787409700723e-05, 'epoch': 1.03}\n",
      "{'loss': 0.0, 'grad_norm': 5.016752766096033e-06, 'learning_rate': 6.532507739938081e-05, 'epoch': 1.04}\n",
      "{'loss': 0.0, 'grad_norm': 2.3621156231001805e-07, 'learning_rate': 6.49122807017544e-05, 'epoch': 1.05}\n",
      "{'loss': 0.0, 'grad_norm': 1.2667730686644063e-07, 'learning_rate': 6.449948400412798e-05, 'epoch': 1.07}\n",
      "{'loss': 0.0, 'grad_norm': 1.1253678167122416e-07, 'learning_rate': 6.408668730650154e-05, 'epoch': 1.08}\n",
      "{'loss': 0.0, 'grad_norm': 4.225732368468016e-07, 'learning_rate': 6.367389060887513e-05, 'epoch': 1.09}\n",
      "{'loss': 0.0, 'grad_norm': 4.36743403042783e-06, 'learning_rate': 6.326109391124871e-05, 'epoch': 1.1}\n",
      "{'loss': 0.0, 'grad_norm': 5.173980639483489e-07, 'learning_rate': 6.28482972136223e-05, 'epoch': 1.11}\n",
      "{'loss': 0.0, 'grad_norm': 4.2204210330965e-06, 'learning_rate': 6.243550051599587e-05, 'epoch': 1.13}\n",
      "{'loss': 0.0, 'grad_norm': 7.502038670281763e-07, 'learning_rate': 6.202270381836945e-05, 'epoch': 1.14}\n",
      "{'loss': 0.0, 'grad_norm': 1.128080157286604e-06, 'learning_rate': 6.160990712074304e-05, 'epoch': 1.15}\n",
      "{'loss': 0.0, 'grad_norm': 6.0414928157115355e-05, 'learning_rate': 6.119711042311662e-05, 'epoch': 1.16}\n",
      "{'loss': 0.0, 'grad_norm': 9.525837754154054e-07, 'learning_rate': 6.078431372549019e-05, 'epoch': 1.18}\n",
      "{'loss': 0.0, 'grad_norm': 0.0001282033190364018, 'learning_rate': 6.0371517027863775e-05, 'epoch': 1.19}\n",
      "{'loss': 0.0, 'grad_norm': 1.2768962278641993e-06, 'learning_rate': 5.9958720330237364e-05, 'epoch': 1.2}\n",
      "{'loss': 0.0, 'grad_norm': 3.2609626998691965e-08, 'learning_rate': 5.9545923632610946e-05, 'epoch': 1.21}\n",
      "{'loss': 0.0, 'grad_norm': 1.177363273541232e-07, 'learning_rate': 5.913312693498453e-05, 'epoch': 1.23}\n",
      "{'loss': 0.0, 'grad_norm': 7.567834927613148e-07, 'learning_rate': 5.87203302373581e-05, 'epoch': 1.24}\n",
      "{'loss': 0.0, 'grad_norm': 3.6907178468936763e-07, 'learning_rate': 5.8307533539731685e-05, 'epoch': 1.25}\n",
      "{'loss': 0.0, 'grad_norm': 1.9172244236642655e-08, 'learning_rate': 5.789473684210527e-05, 'epoch': 1.26}\n",
      "{'loss': 0.0, 'grad_norm': 1.0210384715492182e-07, 'learning_rate': 5.748194014447885e-05, 'epoch': 1.28}\n",
      "{'loss': 0.0, 'grad_norm': 1.6191887652894366e-06, 'learning_rate': 5.7069143446852424e-05, 'epoch': 1.29}\n",
      "{'loss': 0.0, 'grad_norm': 5.5501974571825485e-08, 'learning_rate': 5.6656346749226006e-05, 'epoch': 1.3}\n",
      "{'loss': 0.0, 'grad_norm': 2.2537824406754225e-07, 'learning_rate': 5.6243550051599595e-05, 'epoch': 1.31}\n",
      "{'loss': 0.0, 'grad_norm': 4.5227054101815156e-08, 'learning_rate': 5.583075335397318e-05, 'epoch': 1.33}\n",
      "{'loss': 0.0, 'grad_norm': 5.198124313210428e-07, 'learning_rate': 5.5417956656346745e-05, 'epoch': 1.34}\n",
      "{'loss': 0.0, 'grad_norm': 8.130999731292832e-07, 'learning_rate': 5.5005159958720334e-05, 'epoch': 1.35}\n",
      "{'loss': 0.0, 'grad_norm': 1.2271854075152078e-06, 'learning_rate': 5.4592363261093916e-05, 'epoch': 1.36}\n",
      "{'loss': 0.0, 'grad_norm': 3.391508869299287e-07, 'learning_rate': 5.41795665634675e-05, 'epoch': 1.37}\n",
      "{'loss': 0.0, 'grad_norm': 4.459238596155046e-07, 'learning_rate': 5.3766769865841073e-05, 'epoch': 1.39}\n",
      "{'loss': 0.0, 'grad_norm': 4.393868380248023e-08, 'learning_rate': 5.3353973168214655e-05, 'epoch': 1.4}\n",
      "{'loss': 0.0, 'grad_norm': 2.280260247289334e-07, 'learning_rate': 5.294117647058824e-05, 'epoch': 1.41}\n",
      "{'loss': 0.0, 'grad_norm': 3.116044524631434e-07, 'learning_rate': 5.252837977296182e-05, 'epoch': 1.42}\n",
      "{'loss': 0.0, 'grad_norm': 4.513859721555491e-07, 'learning_rate': 5.2115583075335395e-05, 'epoch': 1.44}\n",
      "{'loss': 0.0, 'grad_norm': 1.1700697655214753e-07, 'learning_rate': 5.170278637770898e-05, 'epoch': 1.45}\n",
      "{'loss': 0.0, 'grad_norm': 5.093410209155991e-07, 'learning_rate': 5.128998968008256e-05, 'epoch': 1.46}\n",
      "{'loss': 0.0, 'grad_norm': 4.290022204145316e-08, 'learning_rate': 5.087719298245615e-05, 'epoch': 1.47}\n",
      "{'loss': 0.0, 'grad_norm': 1.129858784310045e-08, 'learning_rate': 5.046439628482973e-05, 'epoch': 1.49}\n",
      "{'loss': 0.0, 'grad_norm': 3.0252400392782874e-05, 'learning_rate': 5.0051599587203305e-05, 'epoch': 1.5}\n",
      "{'loss': 0.0, 'grad_norm': 4.864404218096752e-06, 'learning_rate': 4.963880288957689e-05, 'epoch': 1.51}\n",
      "{'loss': 0.0, 'grad_norm': 9.086421414394863e-06, 'learning_rate': 4.922600619195047e-05, 'epoch': 1.52}\n",
      "{'loss': 0.0, 'grad_norm': 1.1679169631406694e-07, 'learning_rate': 4.8813209494324044e-05, 'epoch': 1.54}\n",
      "{'loss': 0.0, 'grad_norm': 1.924164507727255e-07, 'learning_rate': 4.840041279669763e-05, 'epoch': 1.55}\n",
      "{'loss': 0.0, 'grad_norm': 1.7776715139916632e-06, 'learning_rate': 4.798761609907121e-05, 'epoch': 1.56}\n",
      "{'loss': 0.0, 'grad_norm': 5.8460204854782205e-06, 'learning_rate': 4.757481940144479e-05, 'epoch': 1.57}\n",
      "{'loss': 0.0, 'grad_norm': 3.920247036148794e-05, 'learning_rate': 4.716202270381837e-05, 'epoch': 1.59}\n",
      "{'loss': 0.0, 'grad_norm': 4.565469225781271e-06, 'learning_rate': 4.6749226006191954e-05, 'epoch': 1.6}\n",
      "{'loss': 0.0, 'grad_norm': 4.707451637386839e-07, 'learning_rate': 4.633642930856553e-05, 'epoch': 1.61}\n",
      "{'loss': 0.0, 'grad_norm': 9.456345395619792e-08, 'learning_rate': 4.592363261093912e-05, 'epoch': 1.62}\n",
      "{'loss': 0.0, 'grad_norm': 1.0717944576299487e-07, 'learning_rate': 4.551083591331269e-05, 'epoch': 1.63}\n",
      "{'loss': 0.0, 'grad_norm': 3.804623815995001e-07, 'learning_rate': 4.5098039215686275e-05, 'epoch': 1.65}\n",
      "{'loss': 0.0, 'grad_norm': 5.039527763983642e-07, 'learning_rate': 4.468524251805986e-05, 'epoch': 1.66}\n",
      "{'loss': 0.0, 'grad_norm': 2.1047696918685688e-07, 'learning_rate': 4.427244582043344e-05, 'epoch': 1.67}\n",
      "{'loss': 0.0, 'grad_norm': 4.0224443864644854e-07, 'learning_rate': 4.3859649122807014e-05, 'epoch': 1.68}\n",
      "{'loss': 0.0, 'grad_norm': 6.473713654031599e-08, 'learning_rate': 4.34468524251806e-05, 'epoch': 1.7}\n",
      "{'loss': 0.0, 'grad_norm': 6.04808150228564e-08, 'learning_rate': 4.303405572755418e-05, 'epoch': 1.71}\n",
      "{'loss': 0.0, 'grad_norm': 2.0610335127457802e-07, 'learning_rate': 4.262125902992776e-05, 'epoch': 1.72}\n",
      "{'loss': 0.0, 'grad_norm': 2.7539729785530653e-07, 'learning_rate': 4.220846233230135e-05, 'epoch': 1.73}\n",
      "{'loss': 0.0, 'grad_norm': 4.19662865169812e-05, 'learning_rate': 4.1795665634674924e-05, 'epoch': 1.75}\n",
      "{'loss': 0.0, 'grad_norm': 3.7001632335886825e-07, 'learning_rate': 4.1382868937048506e-05, 'epoch': 1.76}\n",
      "{'loss': 0.0, 'grad_norm': 6.327381356641126e-07, 'learning_rate': 4.097007223942209e-05, 'epoch': 1.77}\n",
      "{'loss': 0.0, 'grad_norm': 2.5944595108740032e-05, 'learning_rate': 4.055727554179567e-05, 'epoch': 1.78}\n",
      "{'loss': 0.0, 'grad_norm': 0.00011095835361629725, 'learning_rate': 4.0144478844169246e-05, 'epoch': 1.8}\n",
      "{'loss': 0.0, 'grad_norm': 9.366401627630694e-07, 'learning_rate': 3.9731682146542834e-05, 'epoch': 1.81}\n",
      "{'loss': 0.0, 'grad_norm': 2.881681382405077e-07, 'learning_rate': 3.931888544891641e-05, 'epoch': 1.82}\n",
      "{'loss': 0.0, 'grad_norm': 1.6389128631999483e-07, 'learning_rate': 3.890608875128999e-05, 'epoch': 1.83}\n",
      "{'loss': 0.0, 'grad_norm': 1.372772686636381e-07, 'learning_rate': 3.8493292053663574e-05, 'epoch': 1.85}\n",
      "{'loss': 0.0, 'grad_norm': 7.912065029813675e-07, 'learning_rate': 3.8080495356037155e-05, 'epoch': 1.86}\n",
      "{'loss': 0.0, 'grad_norm': 4.3456626741544824e-08, 'learning_rate': 3.766769865841073e-05, 'epoch': 1.87}\n",
      "{'loss': 0.0, 'grad_norm': 2.5240271384063817e-07, 'learning_rate': 3.725490196078432e-05, 'epoch': 1.88}\n",
      "{'loss': 0.0, 'grad_norm': 3.233300276406226e-07, 'learning_rate': 3.6842105263157895e-05, 'epoch': 1.89}\n",
      "{'loss': 0.0, 'grad_norm': 1.4540363224568864e-07, 'learning_rate': 3.642930856553148e-05, 'epoch': 1.91}\n",
      "{'loss': 0.0, 'grad_norm': 2.3839317009333172e-07, 'learning_rate': 3.601651186790506e-05, 'epoch': 1.92}\n",
      "{'loss': 0.0, 'grad_norm': 1.2317181017351686e-06, 'learning_rate': 3.560371517027864e-05, 'epoch': 1.93}\n",
      "{'loss': 0.0, 'grad_norm': 1.4459273245392978e-07, 'learning_rate': 3.5190918472652216e-05, 'epoch': 1.94}\n",
      "{'loss': 0.0, 'grad_norm': 1.5671201936129364e-07, 'learning_rate': 3.4778121775025805e-05, 'epoch': 1.96}\n",
      "{'loss': 0.0, 'grad_norm': 4.150790644530389e-08, 'learning_rate': 3.436532507739939e-05, 'epoch': 1.97}\n",
      "{'loss': 0.0, 'grad_norm': 0.0005242384504526854, 'learning_rate': 3.395252837977296e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0, 'grad_norm': 2.004077828132722e-07, 'learning_rate': 3.3539731682146544e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcdf0333653d4a7882bd54b437203588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/808 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.5984133006650154e-08, 'eval_accuracy': 1.0, 'eval_f1': 1.0, 'eval_runtime': 231.4244, 'eval_samples_per_second': 13.957, 'eval_steps_per_second': 3.491, 'epoch': 2.0}\n",
      "{'loss': 0.0, 'grad_norm': 1.1413741418664358e-07, 'learning_rate': 3.3126934984520126e-05, 'epoch': 2.01}\n",
      "{'loss': 0.0, 'grad_norm': 8.953241376730148e-06, 'learning_rate': 3.271413828689371e-05, 'epoch': 2.02}\n",
      "{'loss': 0.0, 'grad_norm': 4.606088168657152e-07, 'learning_rate': 3.230134158926729e-05, 'epoch': 2.03}\n",
      "{'loss': 0.0, 'grad_norm': 4.8401695096345065e-08, 'learning_rate': 3.188854489164087e-05, 'epoch': 2.04}\n",
      "{'loss': 0.0, 'grad_norm': 2.4661881070642266e-07, 'learning_rate': 3.147574819401445e-05, 'epoch': 2.06}\n",
      "{'loss': 0.0, 'grad_norm': 5.339597919373773e-07, 'learning_rate': 3.106295149638803e-05, 'epoch': 2.07}\n",
      "{'loss': 0.0, 'grad_norm': 3.9440166688109457e-07, 'learning_rate': 3.065015479876161e-05, 'epoch': 2.08}\n",
      "{'loss': 0.0, 'grad_norm': 7.583768137919833e-07, 'learning_rate': 3.0237358101135193e-05, 'epoch': 2.09}\n",
      "{'loss': 0.0, 'grad_norm': 1.927459925354924e-05, 'learning_rate': 2.9824561403508772e-05, 'epoch': 2.11}\n",
      "{'loss': 0.0, 'grad_norm': 4.441253054210392e-08, 'learning_rate': 2.9411764705882354e-05, 'epoch': 2.12}\n",
      "{'loss': 0.0, 'grad_norm': 5.265531299869508e-08, 'learning_rate': 2.8998968008255932e-05, 'epoch': 2.13}\n",
      "{'loss': 0.0, 'grad_norm': 4.607551090884954e-06, 'learning_rate': 2.8586171310629518e-05, 'epoch': 2.14}\n",
      "{'loss': 0.0, 'grad_norm': 1.1118105192053918e-07, 'learning_rate': 2.8173374613003096e-05, 'epoch': 2.15}\n",
      "{'loss': 0.0, 'grad_norm': 3.1040595871445475e-08, 'learning_rate': 2.776057791537668e-05, 'epoch': 2.17}\n",
      "{'loss': 0.0, 'grad_norm': 6.104888683466925e-08, 'learning_rate': 2.7347781217750257e-05, 'epoch': 2.18}\n",
      "{'loss': 0.0, 'grad_norm': 5.97199800722592e-07, 'learning_rate': 2.693498452012384e-05, 'epoch': 2.19}\n",
      "{'loss': 0.0, 'grad_norm': 2.8419025355219674e-08, 'learning_rate': 2.6522187822497424e-05, 'epoch': 2.2}\n",
      "{'loss': 0.0, 'grad_norm': 2.4006675403143163e-07, 'learning_rate': 2.6109391124871003e-05, 'epoch': 2.22}\n",
      "{'loss': 0.0, 'grad_norm': 2.246290478069568e-07, 'learning_rate': 2.5696594427244585e-05, 'epoch': 2.23}\n",
      "{'loss': 0.0, 'grad_norm': 4.705765149992658e-06, 'learning_rate': 2.5283797729618164e-05, 'epoch': 2.24}\n",
      "{'loss': 0.0, 'grad_norm': 1.1040011571594732e-07, 'learning_rate': 2.4871001031991746e-05, 'epoch': 2.25}\n",
      "{'loss': 0.0, 'grad_norm': 2.497516682353762e-08, 'learning_rate': 2.4458204334365324e-05, 'epoch': 2.27}\n",
      "{'loss': 0.0, 'grad_norm': 3.144838274238282e-07, 'learning_rate': 2.4045407636738906e-05, 'epoch': 2.28}\n",
      "{'loss': 0.0, 'grad_norm': 4.439259100763593e-06, 'learning_rate': 2.3632610939112488e-05, 'epoch': 2.29}\n",
      "{'loss': 0.0, 'grad_norm': 1.0054244370394372e-07, 'learning_rate': 2.3219814241486067e-05, 'epoch': 2.3}\n",
      "{'loss': 0.0, 'grad_norm': 3.7206209668738666e-08, 'learning_rate': 2.280701754385965e-05, 'epoch': 2.32}\n",
      "{'loss': 0.0, 'grad_norm': 3.6663571734152356e-08, 'learning_rate': 2.2394220846233234e-05, 'epoch': 2.33}\n",
      "{'loss': 0.0, 'grad_norm': 6.617094072680629e-08, 'learning_rate': 2.1981424148606813e-05, 'epoch': 2.34}\n",
      "{'loss': 0.0, 'grad_norm': 9.684832548373379e-06, 'learning_rate': 2.1568627450980395e-05, 'epoch': 2.35}\n",
      "{'loss': 0.0, 'grad_norm': 0.00018756373901851475, 'learning_rate': 2.1155830753353977e-05, 'epoch': 2.37}\n",
      "{'loss': 0.0, 'grad_norm': 6.915223593750852e-08, 'learning_rate': 2.0743034055727555e-05, 'epoch': 2.38}\n",
      "{'loss': 0.0, 'grad_norm': 4.6049837010286865e-07, 'learning_rate': 2.0330237358101137e-05, 'epoch': 2.39}\n",
      "{'loss': 0.0, 'grad_norm': 2.9324471029212873e-07, 'learning_rate': 1.9917440660474716e-05, 'epoch': 2.4}\n",
      "{'loss': 0.0, 'grad_norm': 1.5502365613428992e-08, 'learning_rate': 1.9504643962848298e-05, 'epoch': 2.41}\n",
      "{'loss': 0.0, 'grad_norm': 5.778116474175476e-07, 'learning_rate': 1.909184726522188e-05, 'epoch': 2.43}\n",
      "{'loss': 0.0, 'grad_norm': 6.314589029443596e-08, 'learning_rate': 1.867905056759546e-05, 'epoch': 2.44}\n",
      "{'loss': 0.0, 'grad_norm': 1.434162157920582e-07, 'learning_rate': 1.826625386996904e-05, 'epoch': 2.45}\n",
      "{'loss': 0.0, 'grad_norm': 6.682464004370559e-08, 'learning_rate': 1.7853457172342623e-05, 'epoch': 2.46}\n",
      "{'loss': 0.0, 'grad_norm': 6.405170438483765e-07, 'learning_rate': 1.74406604747162e-05, 'epoch': 2.48}\n",
      "{'loss': 0.0, 'grad_norm': 1.7221707821590826e-05, 'learning_rate': 1.7027863777089783e-05, 'epoch': 2.49}\n",
      "{'loss': 0.0, 'grad_norm': 4.350163251842787e-08, 'learning_rate': 1.6615067079463365e-05, 'epoch': 2.5}\n",
      "{'loss': 0.0, 'grad_norm': 1.3804103105030663e-07, 'learning_rate': 1.6202270381836944e-05, 'epoch': 2.51}\n",
      "{'loss': 0.0, 'grad_norm': 1.5909716921669315e-07, 'learning_rate': 1.5789473684210526e-05, 'epoch': 2.53}\n",
      "{'loss': 0.0, 'grad_norm': 4.7423636573284966e-08, 'learning_rate': 1.5376676986584108e-05, 'epoch': 2.54}\n",
      "{'loss': 0.0, 'grad_norm': 3.6855786333944707e-07, 'learning_rate': 1.4963880288957688e-05, 'epoch': 2.55}\n",
      "{'loss': 0.0, 'grad_norm': 1.0543668338414136e-07, 'learning_rate': 1.4551083591331268e-05, 'epoch': 2.56}\n",
      "{'loss': 0.0, 'grad_norm': 2.943266963484348e-07, 'learning_rate': 1.4138286893704852e-05, 'epoch': 2.58}\n",
      "{'loss': 0.0, 'grad_norm': 1.1163744062514525e-07, 'learning_rate': 1.3725490196078432e-05, 'epoch': 2.59}\n",
      "{'loss': 0.0, 'grad_norm': 7.515151878578763e-07, 'learning_rate': 1.3312693498452014e-05, 'epoch': 2.6}\n",
      "{'loss': 0.0, 'grad_norm': 6.05443801759975e-07, 'learning_rate': 1.2899896800825595e-05, 'epoch': 2.61}\n",
      "{'loss': 0.0, 'grad_norm': 2.8071036695109797e-07, 'learning_rate': 1.2487100103199175e-05, 'epoch': 2.63}\n",
      "{'loss': 0.0, 'grad_norm': 1.0763989166662213e-06, 'learning_rate': 1.2074303405572757e-05, 'epoch': 2.64}\n",
      "{'loss': 0.0, 'grad_norm': 1.4081003882893128e-06, 'learning_rate': 1.1661506707946337e-05, 'epoch': 2.65}\n",
      "{'loss': 0.0, 'grad_norm': 8.533601913995881e-08, 'learning_rate': 1.1248710010319918e-05, 'epoch': 2.66}\n",
      "{'loss': 0.0, 'grad_norm': 1.5983405887709523e-07, 'learning_rate': 1.08359133126935e-05, 'epoch': 2.67}\n",
      "{'loss': 0.0, 'grad_norm': 3.9001051277409715e-08, 'learning_rate': 1.042311661506708e-05, 'epoch': 2.69}\n",
      "{'loss': 0.0, 'grad_norm': 3.562562937986513e-07, 'learning_rate': 1.001031991744066e-05, 'epoch': 2.7}\n",
      "{'loss': 0.0, 'grad_norm': 2.295275010055775e-07, 'learning_rate': 9.597523219814242e-06, 'epoch': 2.71}\n",
      "{'loss': 0.0, 'grad_norm': 2.661952578364435e-07, 'learning_rate': 9.184726522187823e-06, 'epoch': 2.72}\n",
      "{'loss': 0.0, 'grad_norm': 1.2224708143548924e-06, 'learning_rate': 8.771929824561403e-06, 'epoch': 2.74}\n",
      "{'loss': 0.0, 'grad_norm': 3.905156020778122e-08, 'learning_rate': 8.359133126934985e-06, 'epoch': 2.75}\n",
      "{'loss': 0.0, 'grad_norm': 4.594451638695318e-06, 'learning_rate': 7.946336429308567e-06, 'epoch': 2.76}\n",
      "{'loss': 0.0, 'grad_norm': 4.215313674649224e-05, 'learning_rate': 7.533539731682147e-06, 'epoch': 2.77}\n",
      "{'loss': 0.0, 'grad_norm': 1.3969435030958266e-07, 'learning_rate': 7.120743034055728e-06, 'epoch': 2.79}\n",
      "{'loss': 0.0, 'grad_norm': 8.35492812711891e-08, 'learning_rate': 6.7079463364293095e-06, 'epoch': 2.8}\n",
      "{'loss': 0.0, 'grad_norm': 3.0717354093212634e-05, 'learning_rate': 6.29514963880289e-06, 'epoch': 2.81}\n",
      "{'loss': 0.0, 'grad_norm': 9.291280633760834e-08, 'learning_rate': 5.882352941176471e-06, 'epoch': 2.82}\n",
      "{'loss': 0.0, 'grad_norm': 1.8491229880623905e-08, 'learning_rate': 5.469556243550051e-06, 'epoch': 2.84}\n",
      "{'loss': 0.0, 'grad_norm': 4.083090971107595e-06, 'learning_rate': 5.056759545923633e-06, 'epoch': 2.85}\n",
      "{'loss': 0.0, 'grad_norm': 6.631069737750295e-08, 'learning_rate': 4.643962848297214e-06, 'epoch': 2.86}\n",
      "{'loss': 0.0, 'grad_norm': 1.5250878959705005e-07, 'learning_rate': 4.231166150670795e-06, 'epoch': 2.87}\n",
      "{'loss': 0.0, 'grad_norm': 3.544053015502868e-07, 'learning_rate': 3.818369453044376e-06, 'epoch': 2.89}\n",
      "{'loss': 0.0, 'grad_norm': 4.423027277766778e-08, 'learning_rate': 3.4055727554179566e-06, 'epoch': 2.9}\n",
      "{'loss': 0.0, 'grad_norm': 5.092069699230706e-08, 'learning_rate': 2.9927760577915377e-06, 'epoch': 2.91}\n",
      "{'loss': 0.0, 'grad_norm': 9.554145435686223e-06, 'learning_rate': 2.5799793601651184e-06, 'epoch': 2.92}\n",
      "{'loss': 0.0, 'grad_norm': 2.7416731995799637e-07, 'learning_rate': 2.1671826625387e-06, 'epoch': 2.93}\n",
      "{'loss': 0.0, 'grad_norm': 7.289337133897789e-08, 'learning_rate': 1.7543859649122807e-06, 'epoch': 2.95}\n",
      "{'loss': 0.0, 'grad_norm': 1.0076762890776081e-07, 'learning_rate': 1.3415892672858617e-06, 'epoch': 2.96}\n",
      "{'loss': 0.0, 'grad_norm': 7.027228576816924e-08, 'learning_rate': 9.287925696594427e-07, 'epoch': 2.97}\n",
      "{'loss': 0.0, 'grad_norm': 8.581190513723413e-07, 'learning_rate': 5.159958720330238e-07, 'epoch': 2.98}\n",
      "{'loss': 0.0, 'grad_norm': 1.388831515214406e-05, 'learning_rate': 1.0319917440660474e-07, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8080c33f4daa4baa9625d0a676a5c4d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/808 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.6572919864520372e-08, 'eval_accuracy': 1.0, 'eval_f1': 1.0, 'eval_runtime': 263.5311, 'eval_samples_per_second': 12.257, 'eval_steps_per_second': 3.066, 'epoch': 3.0}\n",
      "{'train_runtime': 36364.1084, 'train_samples_per_second': 1.066, 'train_steps_per_second': 0.133, 'train_loss': 0.0013553814143949456, 'epoch': 3.0}\n",
      "Done! Model + LoRA adapter saved to: ./lora_vuln_model_seqcls\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Hugging Face imports\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments, \n",
    "    Trainer\n",
    ")\n",
    "\n",
    "# PEFT imports\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# ==========================================\n",
    "# 0) Label Mapping\n",
    "# ==========================================\n",
    "label2id = {\"safe\": 0, \"vulnerable\": 1}\n",
    "\n",
    "def encode_labels(example):\n",
    "    example[\"label\"] = label2id[example[\"label\"]]\n",
    "    return example\n",
    "\n",
    "# ==========================================\n",
    "# 1) Load Dataset (All Juliet)\n",
    "# ==========================================\n",
    "data_files = \"juliet_dataset.csv\"\n",
    "raw_dataset = load_dataset(\"csv\", data_files=data_files)\n",
    "\n",
    "# Split into train/test\n",
    "split_data = raw_dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = split_data[\"train\"]\n",
    "eval_dataset  = split_data[\"test\"]\n",
    "\n",
    "# Map labels from string -> int\n",
    "train_dataset = train_dataset.map(encode_labels)\n",
    "eval_dataset  = eval_dataset.map(encode_labels)\n",
    "\n",
    "print(\"Train dataset size:\", len(train_dataset))\n",
    "print(\"Eval dataset size:\",  len(eval_dataset))\n",
    "\n",
    "# ==========================================\n",
    "# 2) Base Model Path & Tokenizer\n",
    "# ==========================================\n",
    "base_model_path = \"/Users/ehsan/.llama/checkpoints/Llama3.2-1B-hf\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_path)\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# ==========================================\n",
    "# 3) Tokenization\n",
    "# ==========================================\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"code\"], truncation=True, max_length=256)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "eval_dataset  = eval_dataset.map(tokenize_function,  batched=True)\n",
    "\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "eval_dataset.set_format(\"torch\",  columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "# ==========================================\n",
    "# 4) Data Collator\n",
    "# ==========================================\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"longest\")\n",
    "\n",
    "# ==========================================\n",
    "# 5) Compute Metrics\n",
    "# ==========================================\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    return {\"accuracy\": acc, \"f1\": f1}\n",
    "\n",
    "# ==========================================\n",
    "# 6) Load Base Model & LoRA\n",
    "# ==========================================\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    base_model_path,\n",
    "    num_labels=2,  # If you have more classes, adjust\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "print(\"LoRA-wrapped model created.\")\n",
    "\n",
    "# ==========================================\n",
    "# 7) Hyperparameters & Training\n",
    "# ==========================================\n",
    "num_train_epochs = 3\n",
    "learning_rate    = 1e-4\n",
    "batch_size       = 4\n",
    "grad_accum_steps = 2\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./checkpoints/llama_vuln_lora\",\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=grad_accum_steps,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=20,\n",
    "    fp16=False,       # If on a GPU with mixed precision, set True\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 8) Train & Save\n",
    "# ==========================================\n",
    "trainer.train()\n",
    "\n",
    "save_path = \"./lora_vuln_model_seqcls\"\n",
    "trainer.save_model(save_path)\n",
    "print(f\"Done! Model + LoRA adapter saved to: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
